{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc20_13TeV_MC_PowhegPythia8EvtGen_NNPDF3_AZNLO_ggZH125_vvbb.root already exists, skipping download.\n",
      "data_1.root already exists, skipping download.\n",
      "data_2.root already exists, skipping download.\n",
      "data_3.root already exists, skipping download.\n",
      "data_4.root already exists, skipping download.\n",
      "Output written to files/ggZH125_vvbb/NOSYS.root\n",
      "Output written to files/ggZH125_vvbb/JET_PT_1UP.root\n",
      "Output written to files/ggZH125_vvbb/JET_PT_1DOWN.root\n",
      "Output written to jetjet_1.root\n",
      "Output written to jetjet_2.root\n",
      "Output written to jetjet_3.root\n",
      "Output written to jetjet_4.root\n",
      "Merged file written to files/bkg/NOSYS.root\n"
     ]
    }
   ],
   "source": [
    "#!/bin/env python\n",
    "import uproot\n",
    "import numpy as np\n",
    "import vector\n",
    "import subprocess\n",
    "import os\n",
    "import csv\n",
    "\n",
    "files = {\n",
    "    \"mc20_13TeV_MC_PowhegPythia8EvtGen_NNPDF3_AZNLO_ggZH125_vvbb.root\": \"https://opendata.cern.ch/record/80012/files/mc20_13TeV_MC_PowhegPythia8EvtGen_NNPDF3_AZNLO_ggZH125_vvbb_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_0.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_1.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_1\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_2.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_2\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_3.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_3\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_4.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_4\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_5.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_5\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_6.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_6\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_0.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ0WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ0WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ1WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ1WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ2WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ3WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ3WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ4WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ4WithSW_file_index.json_0\",\n",
    "    # \"mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ5WithSW.root\": \"https://opendata.cern.ch/record/80014/files/mc20_13TeV_MC_Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ5WithSW_file_index.json_0\",\n",
    "    \"data_1.root\": \"https://opendata.cern.ch/record/80001/files/data16_13TeV_Run_00296939_file_index.json_7\",\n",
    "    \"data_2.root\": \"https://opendata.cern.ch/record/80001/files/data16_13TeV_Run_00296939_file_index.json_8\",\n",
    "    \"data_3.root\": \"https://opendata.cern.ch/record/80001/files/data16_13TeV_Run_00296939_file_index.json_9\",\n",
    "    \"data_4.root\": \"https://opendata.cern.ch/record/80001/files/data16_13TeV_Run_00296939_file_index.json_10\",\n",
    "}\n",
    "\n",
    "\n",
    "# # https://opendata.atlas.cern/docs/data/for_research/metadata\n",
    "# # https://opendata.atlas.cern/files/metadata.csv\n",
    "# def get_weights(file):\n",
    "#     file = file.replace(\"mc20_13TeV_MC_\", \"\").replace(\".root\", \"\")\n",
    "#     with open(\"metadata.csv\", mode=\"r\") as csv_file:\n",
    "#         reader = csv.reader(csv_file)\n",
    "#         for row in reader:\n",
    "#             if file in str(row[1]):\n",
    "#                 print(row)\n",
    "#                 w = float(row[3]) * float(row[3]) / float(row[7])\n",
    "#     return w\n",
    "\n",
    "\n",
    "def download_files():\n",
    "    \"\"\"\n",
    "    Downloads required ROOT files using wget and saves them with specified names.\n",
    "    Suppresses wget output.\n",
    "    \"\"\"\n",
    "    for filename, url in files.items():\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            with open(os.devnull, \"w\") as devnull:  # Suppress output\n",
    "                subprocess.run(\n",
    "                    [\"wget\", \"-O\", filename, url],\n",
    "                    stdout=devnull,\n",
    "                    stderr=devnull,\n",
    "                    check=True,\n",
    "                )\n",
    "        else:\n",
    "            print(f\"{filename} already exists, skipping download.\")\n",
    "\n",
    "\n",
    "def make_ntuple(input_file, output_file, weight, unc=1.0):\n",
    "    f = uproot.open(input_file)\n",
    "    btag = f[\"CollectionTree\"][\"BTagging_AntiKt4EMPFlowAuxDyn.GN2v00_pb\"].array(\n",
    "        library=\"np\"\n",
    "    )\n",
    "    jets_pt = f[\"CollectionTree\"][\"AnalysisJetsAuxDyn.pt\"].array(library=\"np\")\n",
    "    jets_eta = f[\"CollectionTree\"][\"AnalysisJetsAuxDyn.eta\"].array(library=\"np\")\n",
    "    jets_phi = f[\"CollectionTree\"][\"AnalysisJetsAuxDyn.phi\"].array(library=\"np\")\n",
    "    jets_m = f[\"CollectionTree\"][\"AnalysisJetsAuxDyn.m\"].array(library=\"np\")\n",
    "\n",
    "    vars = [\n",
    "        \"j1_pt\",\n",
    "        \"j1_eta\",\n",
    "        \"j1_phi\",\n",
    "        \"j1_m\",\n",
    "        \"j2_pt\",\n",
    "        \"j2_eta\",\n",
    "        \"j2_phi\",\n",
    "        \"j2_m\",\n",
    "        \"h_pt\",\n",
    "        \"h_eta\",\n",
    "        \"h_phi\",\n",
    "        \"h_m\",\n",
    "        \"weight\",\n",
    "        \"bool_btag_1\",\n",
    "        \"bool_btag_2\",\n",
    "        \"my_sf_unc_up\",\n",
    "        \"my_sf_unc_down\",\n",
    "    ]\n",
    "\n",
    "    # Initialize ntup with keys for each systematic variation\n",
    "    ntup = {}\n",
    "    for v in vars:\n",
    "        ntup[v] = []\n",
    "    for event in range(len(jets_pt)):\n",
    "        # no jet trigger in opendata...\n",
    "        jet_indices = np.arange(len(jets_pt[event]))\n",
    "\n",
    "        if len(jet_indices) < 2:\n",
    "            continue\n",
    "        # Select jets with b-tags above the threshold\n",
    "        btag_indices = np.where(btag[event] > 0.85)[0]\n",
    "\n",
    "        # # Skip events with no b-tagged jets to keep test files small\n",
    "        if len(btag_indices) < 1:\n",
    "            continue\n",
    "\n",
    "        btag_1 = len(btag_indices) == 1  # Exactly one b-tag\n",
    "        btag_2 = len(btag_indices) >= 2  # Two or more b-tags\n",
    "\n",
    "        # Assign the first b-tagged jet\n",
    "        j1_idx = 0\n",
    "        j1 = vector.obj(\n",
    "            pt=jets_pt[event][j1_idx] * unc,\n",
    "            eta=jets_eta[event][j1_idx],\n",
    "            phi=jets_phi[event][j1_idx],\n",
    "            mass=jets_m[event][j1_idx],\n",
    "        )\n",
    "\n",
    "        # if btag_1:\n",
    "\n",
    "        j2_idx = 1\n",
    "        j2 = vector.obj(\n",
    "            pt=jets_pt[event][j2_idx] * unc,\n",
    "            eta=jets_eta[event][j2_idx],\n",
    "            phi=jets_phi[event][j2_idx],\n",
    "            mass=jets_m[event][j2_idx],\n",
    "        )\n",
    "        h = j1 + j2\n",
    "\n",
    "        # Fill ntuple\n",
    "        ntup[\"j1_pt\"].append(j1.pt)\n",
    "        ntup[\"j1_eta\"].append(j1.eta)\n",
    "        ntup[\"j1_phi\"].append(j1.phi)\n",
    "        ntup[\"j1_m\"].append(j1.mass)\n",
    "\n",
    "        ntup[\"j2_pt\"].append(j2.pt)\n",
    "        ntup[\"j2_eta\"].append(j2.eta)\n",
    "        ntup[\"j2_phi\"].append(j2.phi)\n",
    "        ntup[\"j2_m\"].append(j2.mass)\n",
    "\n",
    "        ntup[\"h_pt\"].append(h.pt)\n",
    "        ntup[\"h_eta\"].append(h.eta)\n",
    "        ntup[\"h_phi\"].append(h.phi)\n",
    "        ntup[\"h_m\"].append(h.mass)\n",
    "\n",
    "        # Append orthogonal btag flags\n",
    "        ntup[\"bool_btag_1\"].append(1 if btag_1 else 0)\n",
    "        ntup[\"bool_btag_2\"].append(1 if btag_2 else 0)\n",
    "\n",
    "        # Append weights\n",
    "        ntup[\"weight\"].append(weight)\n",
    "        ntup[\"my_sf_unc_up\"].append(1.2)\n",
    "        ntup[\"my_sf_unc_down\"].append(0.8)\n",
    "\n",
    "    with uproot.recreate(output_file) as root_file:\n",
    "        root_file[\"FilteredTree\"] = {key: np.array(val) for key, val in ntup.items()}\n",
    "    print(f\"Output written to {output_file}\")\n",
    "\n",
    "\n",
    "def merge_jetjet_files(output_files, merged_file):\n",
    "    merged_data = {}\n",
    "    for output_file in output_files:\n",
    "        with uproot.open(output_file) as f:\n",
    "            tree = f[\"FilteredTree\"]\n",
    "            for branch in tree.keys():\n",
    "                if branch not in merged_data:\n",
    "                    merged_data[branch] = tree[branch].array(library=\"np\")\n",
    "                else:\n",
    "                    merged_data[branch] = np.concatenate(\n",
    "                        [merged_data[branch], tree[branch].array(library=\"np\")]\n",
    "                    )\n",
    "\n",
    "    with uproot.recreate(merged_file) as root_file:\n",
    "        root_file[\"FilteredTree\"] = merged_data\n",
    "    print(f\"Merged file written to {merged_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_files()\n",
    "\n",
    "    output_files = []\n",
    "    for f_name in files:\n",
    "        if \"ggZH125\" in f_name:\n",
    "            make_ntuple(f_name, \"files/ggZH125_vvbb/NOSYS.root\", weight=1e-3, unc=1.0)\n",
    "            make_ntuple(\n",
    "                f_name, \"files/ggZH125_vvbb/JET_PT_1UP.root\", weight=1e-3, unc=1.1\n",
    "            )\n",
    "            make_ntuple(\n",
    "                f_name, \"files/ggZH125_vvbb/JET_PT_1DOWN.root\", weight=1e-3, unc=0.9\n",
    "            )\n",
    "        else:\n",
    "            output_file = f\"jetjet_{f_name.split('_')[-1]}\"\n",
    "            make_ntuple(f_name, output_file, weight=1)\n",
    "            output_files.append(output_file)\n",
    "\n",
    "    merge_jetjet_files(output_files, \"files/data/NOSYS.root\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
